@article{gelmanBayesianWorkflow2020,
  title = {Bayesian Workflow},
  author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and B{\"u}rkner, Paul-Christian and Modr{\'a}k, Martin},
  year = {2020},
  month = {nov},
  abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.},
  archiveprefix = {arXiv},
  eprint = {2011.01808},
  eprinttype = {arxiv},
  file = {/Users/tedgro/Zotero/storage/XEI2Q7F4/Gelman et al. - 2020 - Bayesian Workflow.pdf;/Users/tedgro/Zotero/storage/8Y5YAYXE/2011.html},
  journal = {arXiv:2011.01808 [stat]},
  keywords = {Statistics - Methodology},
  primaryclass = {stat},
}
@article{juarezModelBasedClusteringNonGaussian2010,
  title = {{Model-{{Based Clustering}} of {{Non}}-{{Gaussian Panel Data Based}} on {{Skew}}-t {{Distributions}}}},
  author = {Ju{\'a}rez, Miguel A. and Steel, Mark F. J.},
  year = {2010},
  month = {jan},
  journal = {{Journal of Business \& Economic Statistics}},
  volume = {{28}},
  number = {{1}},
  pages = {{52--66}},
  publisher = {{{Taylor \& Francis}}},
  issn = {{0735-0015}},
  doi = {10.1198/jbes.2009.07145},
  abstract = {{We propose a model-based method to cluster units within a panel. The underlying model is autoregressive and non-Gaussian, allowing for both skewness and fat tails, and the units are clustered according to their dynamic behavior, equilibrium level, and the effect of covariates. Inference is addressed from a Bayesian perspective, and model comparison is conducted using Bayes factors. Particular attention is paid to prior elicitation and posterior propriety. We suggest priors that require little subjective input and have hierarchical structures that enhance inference robustness. We apply our methodology to GDP growth of European regions and to employment growth of Spanish firms.}},
  keywords = {{Autoregressive modeling,Employment growth,GDP growth convergence,Hierarchical prior,Model comparison,Posterior propriety,Skewness}},
  annotation = {{\_eprint: https://doi.org/10.1198/jbes.2009.07145}},
  file = {{/Users/tedgro/Reading/Zotero/storage/EL3ZEJ39/Ju√°rez and Steel - 2010 - Model-Based Clustering of Non-Gaussian Panel Data .pdf;/Users/tedgro/Reading/Zotero/storage/ZFXS2WUD/jbes.2009.html}},
}
@article{vehtariPracticalBayesianModel2017,
  title = {{Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = {sep},
  journal = {{Statistics and Computing}},
  volume = {{27}},
  number = {{5}},
  eprint = {{1507.04544}},
  eprinttype = {{arxiv}},
  pages = {{1413--1432}},
  issn = {{0960-3174, 1573-1375}},
  doi = {{10.1007/s11222-016-9696-4}},
  abstract = {{Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.}},
  archiveprefix = {{arXiv}},
  language = {{en}},
  keywords = {{Statistics - Computation,Statistics - Methodology}},
  file = {{/Users/tedgro/Reading/Zotero/storage/554NNNS2/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf}},
}
@article{arviz_2019,
  doi = {10.21105/joss.01143},
  url = {https://doi.org/10.21105/joss.01143},
  year = {2019},
  publisher = {The Open Journal},
  volume = {4},
  number = {33},
  pages = {1143},
  author = {Ravin Kumar and Colin Carroll and Ari Hartikainen and Osvaldo Martin},
  title = {ArviZ a unified library for exploratory analysis of Bayesian models in Python},
  journal = {Journal of Open Source Software},
}
