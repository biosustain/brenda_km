<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-10-15 Fri 15:50 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Analysing some results</title>
<meta name="author" content="Teddy Groves" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
</style>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Analysing some results</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgd3ee9fc">1. Preliminaries</a></li>
<li><a href="#orgd313ae8">2. Imports</a></li>
<li><a href="#orgdf91264">3. Loading the input data</a></li>
<li><a href="#org0ee9d7f">4. Checking model results</a></li>
<li><a href="#orge86c269">5. Cross validation</a></li>
</ul>
</div>
</div>
<p>
This notebook analyses the results of a model of some BRENDA km data. To generate the results yourself, first make sure you have installed all the dependencies, then run these python scripts:
</p>

<pre class="example" id="org43b07da">
python prepare_data.py
python generate_fake_data.py
python sample.py
</pre>

<div id="outline-container-orgd3ee9fc" class="outline-2">
<h2 id="orgd3ee9fc"><span class="section-number-2">1.</span> Preliminaries</h2>
<div class="outline-text-2" id="text-1">
<p>
First make sure you have already run some models. If you have, there should be
some subfolders in the folder <code>results/runs</code>. We check this with the following
shell command:
</p>

<div class="org-src-container">
<pre class="src src-sh">ls results/runs
</pre>
</div>

<p>
There are some folders there so we are good!
</p>
</div>
</div>

<div id="outline-container-orgd313ae8" class="outline-2">
<h2 id="orgd313ae8"><span class="section-number-2">2.</span> Imports</h2>
<div class="outline-text-2" id="text-2">
<p>
Now we start writing python code for analysis. First some imports
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #5317ac;">import</span> json
<span style="color: #5317ac;">import</span> os
<span style="color: #5317ac;">import</span> warnings

<span style="color: #5317ac;">import</span> arviz <span style="color: #5317ac;">as</span> az
<span style="color: #5317ac;">import</span> numpy <span style="color: #5317ac;">as</span> np
<span style="color: #5317ac;">import</span> pandas <span style="color: #5317ac;">as</span> pd
<span style="color: #5317ac;">from</span> matplotlib <span style="color: #5317ac;">import</span> pyplot <span style="color: #5317ac;">as</span> plt
<span style="color: #5317ac;">from</span> matplotlib.axes._axes <span style="color: #5317ac;">import</span> Axes <span style="color: #5317ac;">as</span> MplAxes
</pre>
</div>
</div>
</div>

<div id="outline-container-orgdf91264" class="outline-2">
<h2 id="orgdf91264"><span class="section-number-2">3.</span> Loading the input data</h2>
<div class="outline-text-2" id="text-3">
<p>
Load a csv table <code>m</code> of prepared measurements.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #00538b;">DATA_DIR</span> = os.path.join(<span style="color: #2544bb;">"data"</span>, <span style="color: #2544bb;">"prepared"</span>, <span style="color: #2544bb;">"tenfold"</span>)
<span style="color: #00538b;">m</span> = pd.read_csv(os.path.join(DATA_DIR, <span style="color: #2544bb;">"input_df.csv"</span>))
</pre>
</div>

<p>
The table's rows report the mean reported value for each study/km combination
we retrieved from the BRENDA database, for the organisms Escherichia coli, Homo
Sapiens and Saccharomyces cerevisiae.
</p>

<p>
Here is what the first row looks like:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python">m.iloc[0]
</pre>
</div>
<pre class="example" id="orgaeb4492">
Unnamed: 0                                        0
ec4                                       1.1.1.100
organism                           Escherichia coli
substrate                                     NADPH
ec_sub                              1.1.1.100|NADPH
org_sub                      Escherichia coli|NADPH
literature                                 [704337]
biology            1.1.1.100|Escherichia coli|NADPH
y                                          -4.60517
n                                                 1
sd                                              NaN
ec4_stan                                          1
organism_stan                                     1
substrate_stan                                    1
ec_sub_stan                                       1
org_sub_stan                                      1
literature_stan                                   1
biology_stan                                      1
Name: 0, dtype: object
</pre>

<p>
Here are the y values in order:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #5317ac;">def</span> <span style="color: #721045;">plot_data</span>(ax: MplAxes, m: pd.DataFrame, obs_col=<span style="color: #2544bb;">"y"</span>):
    x = np.arange(<span style="color: #8f0075;">len</span>(m))
    y = m.sort_values(obs_col)[obs_col]
    ax.scatter(x, y, color=<span style="color: #2544bb;">"black"</span>, s=5, label=<span style="color: #2544bb;">"Observed"</span>)
    ax.get_xaxis().set_ticks([])
    ax.<span style="color: #8f0075;">set</span>(xlabel=<span style="color: #2544bb;">"Ec/substrate/organism in a study"</span>,
           ylabel=<span style="color: #2544bb;">"km ($\ln$ scale)"</span>)
    leg = ax.legend(frameon=<span style="color: #0000c0;">False</span>)
    <span style="color: #5317ac;">return</span> ax

f, ax = plt.subplots()
ax = plot_data(ax, m)
f.savefig(
    os.path.join(<span style="color: #2544bb;">"results"</span>, <span style="color: #2544bb;">"plots"</span>, <span style="color: #2544bb;">"input_data.svg"</span>),
    bbox_inches=<span style="color: #2544bb;">"tight"</span>
)
</pre>
</div>

<p>
:RESULTS:
</p>

<div id="org3a5fc0f" class="figure">
<p><img src="./.ob-jupyter/7cf6715bf9152509a368ec51b6b0561c30df07f3.png" alt="7cf6715bf9152509a368ec51b6b0561c30df07f3.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org0ee9d7f" class="outline-2">
<h2 id="org0ee9d7f"><span class="section-number-2">4.</span> Checking model results</h2>
<div class="outline-text-2" id="text-4">
<p>
Now we choose some files to analyse and load them into arviz <a href="https://arviz-devs.github.io/arviz/api/inference_data.html">InferenceData</a>
objects.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #00538b;">RESULTS_DIR</span> = os.path.join(<span style="color: #2544bb;">"results"</span>, <span style="color: #2544bb;">"runs"</span>, <span style="color: #2544bb;">"blk"</span>)
<span style="color: #00538b;">idata</span> = az.from_netcdf(os.path.join(RESULTS_DIR, <span style="color: #2544bb;">"posterior"</span>, <span style="color: #2544bb;">"idata.nc"</span>))
<span style="color: #00538b;">prior</span> = az.from_netcdf(os.path.join(RESULTS_DIR, <span style="color: #2544bb;">"prior"</span>, <span style="color: #2544bb;">"idata.nc"</span>))
<span style="color: #00538b;">fake</span> = az.from_netcdf(os.path.join(RESULTS_DIR, <span style="color: #2544bb;">"fake"</span>, <span style="color: #2544bb;">"idata.nc"</span>))
idata.add_groups({
   <span style="color: #2544bb;">"prior"</span>: prior.posterior,
   <span style="color: #2544bb;">"fake"</span>: fake.posterior,
   <span style="color: #2544bb;">"observed_data_fake"</span>: fake.observed_data,
   <span style="color: #2544bb;">"sample_stats_prior"</span>: prior.sample_stats
})
idata
</pre>
</div>

<pre class="example">
/Users/tedgro/.pyenv/versions/3.8.6/lib/python3.8/site-packages/arviz/data/inference_data.py:1317: UserWarning: The group fake is not defined in the InferenceData scheme
  warnings.warn(
/Users/tedgro/.pyenv/versions/3.8.6/lib/python3.8/site-packages/arviz/data/inference_data.py:1317: UserWarning: The group observed_data_fake is not defined in the InferenceData scheme
  warnings.warn(
Inference data with groups:
	&gt; posterior
	&gt; log_likelihood
	&gt; sample_stats
	&gt; observed_data
	&gt; prior
	&gt; fake
	&gt; observed_data_fake
	&gt; sample_stats_prior
</pre>


<p>
The next bit of code makes a pandas dataframe containing the marginal 2.5% and
97.5% predictive quantiles for each observation, for the prior, posterior and
fake-data-posterior models, as well as the relevant observed log km.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #00538b;">ppq_prior</span>, <span style="color: #00538b;">ppq_posterior</span>, <span style="color: #00538b;">ppq_fake</span> = (
    idata.get(g)[<span style="color: #2544bb;">"yrep"</span>]
    .quantile([0.025, 0.975], dim=[<span style="color: #2544bb;">"chain"</span>, <span style="color: #2544bb;">"draw"</span>])
    .to_series()
    .unstack(<span style="color: #2544bb;">"quantile"</span>)
    .add_prefix(f<span style="color: #2544bb;">"</span>{g}<span style="color: #2544bb;">_"</span>)
    .rename_axis(<span style="color: #2544bb;">""</span>, axis=1)
    <span style="color: #5317ac;">for</span> g <span style="color: #5317ac;">in</span> (<span style="color: #2544bb;">"prior"</span>, <span style="color: #2544bb;">"posterior"</span>, <span style="color: #2544bb;">"fake"</span>)
)
ppq = ppq_prior.join(ppq_posterior).join(ppq_fake)
ppq[<span style="color: #2544bb;">"obs"</span>] = idata.observed_data[<span style="color: #2544bb;">"y_test"</span>].values
ppq[<span style="color: #2544bb;">"obs_fake"</span>] = idata.observed_data_fake[<span style="color: #2544bb;">"y_test"</span>].values
ppq = ppq.sort_values(<span style="color: #2544bb;">"obs"</span>)
ppq
</pre>
</div>

<pre class="example" id="org24e3e96">
            prior_0.025  prior_0.975  posterior_0.025  posterior_0.975  \
yrep_dim_0                                                               
1165          -7.847306     4.176406       -13.393017        -6.424276   
135           -7.782696     3.902972        -6.582813        -0.101759   
4031          -7.787102     3.821657       -16.086117         3.197087   
4353          -8.103219     4.028205       -11.915835        -3.854086   
3028          -7.791763     3.845696       -12.640320         1.228611   
...                 ...          ...              ...              ...   
5262          -8.062909     4.032168        -6.012040         7.477105   
5691          -8.200756     4.004418        -5.219667         1.685722   
299           -7.903204     4.182943        -3.605605         4.699433   
5648          -7.958700     4.143261         1.439340         8.232254   
5143          -7.899296     3.928554        -4.157994         2.828056   

            fake_0.025  fake_0.975        obs  obs_fake  
yrep_dim_0                                               
1165         -6.279775   -1.592293 -17.777735 -4.224110  
135          -5.991642   -1.630591 -16.436196 -4.141880  
4031         -4.725760    0.647097 -15.855731  0.043783  
4353         -2.135240    2.713712 -15.476242  0.265162  
3028         -6.759330   -0.884686 -14.865333 -4.528010  
...                ...         ...        ...       ...  
5262         -5.246686    0.309686   6.040255 -2.620180  
5691         -3.634911    0.726355   6.492240 -1.913510  
299          -5.198901   -0.589103   6.522093 -2.565750  
5648         -6.388566   -1.837142   6.620919 -4.305300  
5143         -5.626431   -0.802943   7.176002 -3.377470  

[6389 rows x 8 columns]
</pre>


<p>
This code plots these predictive distributions for the prior and posterior
models:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #00538b;">f</span>, <span style="color: #00538b;">axes</span> = plt.subplots(1, 2, sharey=<span style="color: #0000c0;">True</span>, figsize=[15, 5])
axes = axes.ravel()
d = ppq.sort_values(<span style="color: #2544bb;">"obs"</span>)
x = np.arange(<span style="color: #8f0075;">len</span>(d))
<span style="color: #5317ac;">for</span> g, ax <span style="color: #5317ac;">in</span> <span style="color: #8f0075;">zip</span>([<span style="color: #2544bb;">"prior"</span>, <span style="color: #2544bb;">"posterior"</span>], axes):
    ax = plot_data(ax, d, obs_col=<span style="color: #2544bb;">"obs"</span>)
    ax.vlines(
        x, d[f<span style="color: #2544bb;">"</span>{g}<span style="color: #2544bb;">_0.025"</span>], d[f<span style="color: #2544bb;">"</span>{g}<span style="color: #2544bb;">_0.975"</span>],
        color=<span style="color: #2544bb;">"tab:blue"</span>, zorder=0, label=<span style="color: #2544bb;">"2.5%-97.5% interval"</span>
    )
    leg = ax.legend(frameon=<span style="color: #0000c0;">False</span>)
    ax.set_title(g.capitalize())

f.savefig(
    os.path.join(<span style="color: #2544bb;">"results"</span>, <span style="color: #2544bb;">"plots"</span>, <span style="color: #2544bb;">"ppc.svg"</span>),
    bbox_inches=<span style="color: #2544bb;">"tight"</span>
)
</pre>
</div>


<div id="orgf6b6a59" class="figure">
<p><img src="./.ob-jupyter/6cf630bb77131d709a5c9663c691ad1b4b09ecd4.png" alt="6cf630bb77131d709a5c9663c691ad1b4b09ecd4.png" />
</p>
</div>


<p>
It's interesting to compare these plots with the equivalent one for the fake data posterior:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #00538b;">f</span>, <span style="color: #00538b;">ax</span> = plt.subplots(figsize=[8, 5])
d = ppq.sort_values(<span style="color: #2544bb;">"obs_fake"</span>)
x = np.arange(<span style="color: #8f0075;">len</span>(d))
ax = plot_data(ax, d, obs_col=<span style="color: #2544bb;">"obs_fake"</span>)
ax.vlines(
    x, d[<span style="color: #2544bb;">"fake_0.025"</span>], d[<span style="color: #2544bb;">"fake_0.975"</span>],
    color=<span style="color: #2544bb;">"tab:blue"</span>, zorder=0, label=<span style="color: #2544bb;">"2.5%-97.5% interval"</span>
)
leg = ax.legend(frameon=<span style="color: #0000c0;">False</span>)
ax.set_title(<span style="color: #2544bb;">"Fake data posterior predictive distribution"</span>)
f.savefig(
    os.path.join(<span style="color: #2544bb;">"results"</span>, <span style="color: #2544bb;">"plots"</span>, <span style="color: #2544bb;">"ppc_fake.svg"</span>),
    bbox_inches=<span style="color: #2544bb;">"tight"</span>
)
</pre>
</div>


<div id="orgd9e4c8e" class="figure">
<p><img src="./.ob-jupyter/ba7539756502005f0d3d6bba94bc22d96a558a77.png" alt="ba7539756502005f0d3d6bba94bc22d96a558a77.png" />
</p>
</div>


<p>
The posterior predictive distribution for the fake data model looks pretty similar to the real data one - great!
</p>
</div>
</div>

<div id="outline-container-orge86c269" class="outline-2">
<h2 id="orge86c269"><span class="section-number-2">5.</span> Cross validation</h2>
<div class="outline-text-2" id="text-5">
<p>
We can try to evaluate the model's predictive performance using approximate
leave-one-out cross validation.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python">az.loo(idata, pointwise=<span style="color: #0000c0;">True</span>)
</pre>
</div>

<pre class="example">
/Users/tedgro/.pyenv/versions/3.8.6/lib/python3.8/site-packages/arviz/stats/stats.py:655: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.
  warnings.warn(
</pre>

<pre class="example" id="org83c84aa">
Computed from 3200 by 6389 log-likelihood matrix

         Estimate       SE
elpd_loo -12549.28    86.78
p_loo     2681.82        -

There has been a warning during the calculation. Please check the results.
------

Pareto k diagnostic values:
                         Count   Pct.
(-Inf, 0.5]   (good)     5914   92.6%
 (0.5, 0.7]   (ok)        407    6.4%
   (0.7, 1]   (bad)        65    1.0%
   (1, Inf)   (very bad)    3    0.0%
</pre>

<p>
Unfortunately there are quite a few observations with high pareto k values, and arviz raises a warning.
</p>

<p>
To address this issue we also ran exact ten-fold cross validation.
</p>

<p>
The code below checks the results of these finds the posterior mean for
out-of-sample log likelihood for each split in our model and compares the
results with two alternative models:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #00538b;">run_dir</span> = os.path.join(<span style="color: #2544bb;">"results"</span>, <span style="color: #2544bb;">"runs"</span>)
<span style="color: #00538b;">runs</span> = [
    os.path.join(run_dir, s) <span style="color: #5317ac;">for</span> s <span style="color: #5317ac;">in</span> os.listdir(run_dir)
    <span style="color: #5317ac;">if</span> os.path.isdir(os.path.join(run_dir, s))
]
<span style="color: #5317ac;">for</span> run <span style="color: #5317ac;">in</span> <span style="color: #00538b;">runs</span>:
    run_ll = 0
    <span style="color: #00538b;">splits_dir</span> = os.path.join(run, <span style="color: #2544bb;">"splits"</span>)
    <span style="color: #5317ac;">print</span>(f<span style="color: #2544bb;">"calculating out of sample log likelihoods for model </span>{run}<span style="color: #2544bb;">..."</span>)
    <span style="color: #5317ac;">for</span> split <span style="color: #5317ac;">in</span> os.listdir(splits_dir):
        <span style="color: #00538b;">idata</span> = az.from_netcdf(os.path.join(splits_dir, split, <span style="color: #2544bb;">"idata.nc"</span>))
        <span style="color: #00538b;">split_ll</span> = (
            idata.get(<span style="color: #2544bb;">"log_likelihood"</span>)[<span style="color: #2544bb;">"llik"</span>]
            .mean(dim=[<span style="color: #2544bb;">"chain"</span>, <span style="color: #2544bb;">"draw"</span>])
            .values.<span style="color: #8f0075;">sum</span>()
        )
        <span style="color: #5317ac;">print</span>(f<span style="color: #2544bb;">"\t</span>{split}<span style="color: #2544bb;">: </span>{<span style="color: #8f0075;">str</span>(split_ll)}<span style="color: #2544bb;">"</span>)
        run_ll += split_ll
    <span style="color: #5317ac;">print</span>(f<span style="color: #2544bb;">"\ttotal out of sample log likelihood: </span>{run_ll}<span style="color: #2544bb;">"</span>)
</pre>
</div>

<pre class="example">
calculating out of sample log likelihoods for model results/runs/blk...
	split_4: -1477.2729990849998
	split_3: -1481.00882687375
	split_2: -1441.2448831225
	split_5: -1477.1304594875
	split_0: -1467.7910366725
	split_7: -1480.53716923375
	split_9: -1504.9884546787503
	split_8: -1502.4060516825002
	split_6: -1483.4119273775
	split_1: -1515.77739092
	total out of sample log likelihood: -14831.569199133752
calculating out of sample log likelihoods for model results/runs/simple...
	split_4: -2245.9115185025003
	split_3: -2182.5809449999997
	split_2: -2262.4983365774997
	split_5: -2150.721065105
	split_0: -2351.9525779625
	split_7: -2288.8911877974997
	split_9: -2194.1904108999997
	split_8: -2348.7044462475
	split_6: -2389.71007908
	split_1: -2263.04032354
	total out of sample log likelihood: -22678.2008907125
calculating out of sample log likelihoods for model results/runs/really_simple...
	split_4: -1552.20558885
	split_3: -1505.90971685
	split_2: -1551.5482681499998
	split_5: -1470.82288385
	split_0: -1639.23052325
	split_7: -1557.061260825
	split_9: -1516.690492875
	split_8: -1651.7273156750002
	split_6: -1680.8369810999998
	split_1: -1575.714097825
	total out of sample log likelihood: -15701.747129249998
</pre>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Teddy Groves</p>
<p class="date">Created: 2021-10-15 Fri 15:50</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
